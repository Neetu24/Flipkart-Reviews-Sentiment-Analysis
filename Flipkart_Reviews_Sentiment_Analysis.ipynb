{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJCTrCk90A+1y0nBQSvm1i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neetu24/Flipkart-Reviews-Sentiment-Analysis/blob/main/Flipkart_Reviews_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOu_oPF7Ar7H",
        "outputId": "ae13ef7d-dca8-4838-ae32-c08288bffcbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßæ Dataset columns: Index(['review', 'rating'], dtype='object')\n",
            "\n",
            "üìä Sentiment Value Counts:\n",
            "sentiment\n",
            "1    631\n",
            "Name: count, dtype: int64\n",
            "‚ùå ERROR: Dataset contains only one class. Please provide both positive and negative reviews.\n"
          ]
        }
      ],
      "source": [
        "# üì¶ Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import re, string, warnings\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# üì• Load Dataset\n",
        "df = pd.read_csv('/content/flipkart_data.csv')\n",
        "print(\"üßæ Dataset columns:\", df.columns)\n",
        "\n",
        "# üîÑ Rename likely columns\n",
        "for col in df.columns:\n",
        "    if 'review' in col.lower():\n",
        "        df.rename(columns={col: 'review'}, inplace=True)\n",
        "    if 'sentiment' in col.lower() or 'label' in col.lower() or 'rating' in col.lower():\n",
        "        df.rename(columns={col: 'sentiment'}, inplace=True)\n",
        "\n",
        "# üßπ Clean and Filter Data\n",
        "df.dropna(subset=['review', 'sentiment'], inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df['review'] = df['review'].astype(str)\n",
        "\n",
        "# üßº Text Cleaning Function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
        "    text = re.sub(r'\\@\\w+|\\#','', text)\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_review'] = df['review'].apply(clean_text)\n",
        "\n",
        "# üß† Sentiment Encoding\n",
        "df['sentiment'] = df['sentiment'].astype(str).str.strip().str.lower()\n",
        "df['sentiment'] = df['sentiment'].map({\n",
        "    'positive': 1, 'pos': 1, '1': 1, 'yes': 1,\n",
        "    'negative': 0, 'neg': 0, '0': 0, 'no': 0\n",
        "})\n",
        "df.dropna(subset=['sentiment'], inplace=True)\n",
        "df['sentiment'] = df['sentiment'].astype(int)\n",
        "\n",
        "# ‚úÖ Show class distribution\n",
        "print(\"\\nüìä Sentiment Value Counts:\")\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "# Check for at least two classes\n",
        "if df['sentiment'].nunique() < 2:\n",
        "    print(\"‚ùå ERROR: Dataset contains only one class. Please provide both positive and negative reviews.\")\n",
        "else:\n",
        "    # üß† TF-IDF Vectorization\n",
        "    tfidf = TfidfVectorizer(max_features=5000)\n",
        "    X = tfidf.fit_transform(df['clean_review']).toarray()\n",
        "    y = df['sentiment'].values\n",
        "\n",
        "    # üîÄ Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # üìä Sentiment Distribution Plot\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.countplot(x=df['sentiment'])\n",
        "    plt.title('Sentiment Distribution')\n",
        "    plt.xticks([0,1], ['Negative', 'Positive'])\n",
        "    plt.show()\n",
        "\n",
        "    # ‚òÅÔ∏è Word Cloud Generator\n",
        "    def show_wordcloud(data, title=None):\n",
        "        text = ' '.join(data)\n",
        "        if len(text.strip()) == 0:\n",
        "            print(f\"‚ö†Ô∏è No text available to generate word cloud for: {title}\")\n",
        "            return\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(title)\n",
        "        plt.show()\n",
        "\n",
        "    # ‚òÅÔ∏è Generate Word Clouds\n",
        "    if df[df['sentiment']==1].shape[0] > 0:\n",
        "        show_wordcloud(df[df['sentiment']==1]['clean_review'], \"Positive Reviews\")\n",
        "    if df[df['sentiment']==0].shape[0] > 0:\n",
        "        show_wordcloud(df[df['sentiment']==0]['clean_review'], \"Negative Reviews\")\n",
        "\n",
        "    # üìè Review Length Analysis\n",
        "    df['review_len'] = df['clean_review'].apply(lambda x: len(x.split()))\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.boxplot(x='sentiment', y='review_len', data=df)\n",
        "    plt.title('Review Length vs Sentiment')\n",
        "    plt.xticks([0,1], ['Negative', 'Positive'])\n",
        "    plt.show()\n",
        "\n",
        "    # ü§ñ Train Models\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Naive Bayes\": MultinomialNB(),\n",
        "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        \"SVM\": SVC()\n",
        "    }\n",
        "\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        print(f\"\\nüîç {name} Results:\")\n",
        "        print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")\n",
        "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n",
        "    # üß™ Predict Sentiment for New Reviews\n",
        "    final_model = LogisticRegression()\n",
        "    final_model.fit(X_train, y_train)\n",
        "\n",
        "    test_reviews = [\n",
        "        \"Worst product ever! Waste of money!\",\n",
        "        \"Absolutely loved it! Great quality and delivery.\",\n",
        "        \"Not worth the price. Disappointed.\",\n",
        "        \"Amazing features and value for money!\"\n",
        "    ]\n",
        "\n",
        "    cleaned = [clean_text(review) for review in test_reviews]\n",
        "    vec = tfidf.transform(cleaned).toarray()\n",
        "    preds = final_model.predict(vec)\n",
        "\n",
        "    for review, pred in zip(test_reviews, preds):\n",
        "        sentiment = 'Positive ‚úÖ' if pred == 1 else 'Negative ‚ùå'\n",
        "        print(f\"\\nReview: {review}\\nPredicted Sentiment: {sentiment}\")\n"
      ]
    }
  ]
}